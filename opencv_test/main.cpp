#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include <math.h>
#include <string>
#include <vector>
#include <iostream>
#include <opencv2/opencv.hpp>
#include <stdlib.h>
#include <tuple>
#include <conio.h>  
#include <fstream>

#define PI 3.141592653
#define ABS(a)      (((a)<(0))?-(a):(a))
//#define MAX(a,b)    (((a)>(b))?(a):(b)) // already defined by openCV
#define Deg2Rad 0.01745329251 // pi/180
#define Rad2Deg 57.295779546 // 180/pi
#define MAX_RPM 300

#define _WINSOCK_DEPRECATED_NO_WARNINGS


#include <WinSock2.h>
#include <iostream>
#include <fstream>
#include "egm.pb.h" // generated by Google protoc.exe
#pragma comment(lib, "Ws2_32.lib")      // socket lib

#ifdef _DEBUG
#pragma comment(lib, "libprotobufd.lib")
#else
#pragma comment(lib, "libprotobuf.lib") // protobuf lib
#endif

#undef min
#undef max


using namespace cv;
using namespace std;

ofstream myfile;


void Quaternion(float fYaw, float &X, float &Y, float &Z, float &W)
{
	float fRoll = 0.0;
	float fPitch = 0.0;
	fYaw *= Deg2Rad;
	const float fSinPitch(sin(fPitch*0.5F));
	const float fCosPitch(cos(fPitch*0.5F));
	const float fSinYaw(sin(fYaw*0.5F));
	const float fCosYaw(cos(fYaw*0.5F));
	const float fSinRoll(sin(fRoll*0.5F));
	const float fCosRoll(cos(fRoll*0.5F));
	const float fCosPitchCosYaw(fCosPitch*fCosYaw);
	const float fSinPitchSinYaw(fSinPitch*fSinYaw);
	X = fSinRoll * fCosPitchCosYaw - fCosRoll * fSinPitchSinYaw;
	Y = fCosRoll * fSinPitch * fCosYaw + fSinRoll * fCosPitch * fSinYaw;
	Z = fCosRoll * fCosPitch * fSinYaw - fSinRoll * fSinPitch * fCosYaw;
	W = fCosRoll * fCosPitchCosYaw + fSinRoll * fSinPitchSinYaw;
	return;
}
struct myclass {
	bool operator() (cv::Point pt1, cv::Point pt2) { return (pt1.x > pt2.x); }
} object_x;
struct myclass2 {
	bool operator() (cv::Point pt1, cv::Point pt2) { return (pt1.y < pt2.y); }
} object_y;

void vision_process(cv::Mat src, cv::Mat& PO, float& Q1, float& Q2, float& Q3, float& Q4) {
	bool verbose = false;
	Mat dst, result;
	cvtColor(src, dst, CV_GRAY2BGR);
	Canny(dst, result, 50, 150, 3);
	
	float cm_to_pixel = 32.8 / 640;
	//Rotate an Image
	double angle = -90;
	// get rotation matrix for rotating the image around its center
	cv::Point2f center(result.cols / 2.0, result.rows / 2.0);
	cv::Mat rot = cv::getRotationMatrix2D(center, angle, 1.0);
	// determine bounding rectangle
	cv::Rect bbox = cv::RotatedRect(center, result.size(), angle).boundingRect();
	// adjust transformation matrix
	rot.at<double>(0, 2) += bbox.width / 2.0 - center.x;
	rot.at<double>(1, 2) += bbox.height / 2.0 - center.y;

	cv::Mat rot_dst;
	cv::warpAffine(result, rot_dst, rot, bbox.size());
	cv::imwrite("rotated_im.png", rot_dst);

	/**
	* Resize mat
	*/
	const int kNewWidth = 640;
	const int kNewHeight = 480;

	Mat frame;
	resize(rot_dst, frame, cvSize(kNewWidth, kNewHeight));
	cv::imwrite("resized_im.png", frame);

	result = rot_dst.clone();
	if (verbose) {
		cout << "Width : " << result.size().width << endl;
		cout << "Height: " << result.size().height << endl;
	}

	std::vector<double> vec_x;
	std::vector<double> vec_y;
	for (int y = 0; y<result.rows; y++)
	{
		Vec3b* res = result.ptr<Vec3b>(y);
		for (int x = 0; x<result.cols; x++)// x=320
		{
			if (((int)res[x][0]) != 0)
			{
				vec_x.push_back(x);
				vec_y.push_back(y);
			}
		}
	}

	//-------------------------------------------------------------- build matrix
	// Predict the parameters of the parabolic model 

	int no_samples = vec_x.size(); // Number of samples selected same as the selected point size

	cv::Mat A(no_samples, 3, CV_64FC1);
	cv::Mat B(no_samples, 1, CV_64FC1); 

	for (int i = 0; i<no_samples; i++) // sizeof instead all 100
	{
		A.at<double>(i, 0) = vec_x[i] * vec_x[i];
		A.at<double>(i, 1) = vec_x[i];
		A.at<double>(i, 2) = 1.0;
	}
	for (int i = 0; i<no_samples; i++)
	{
		B.at<double>(i, 0) = vec_y[i];
	}

	//--------- RANSAC Line fitting-------------------------------------------------------

	//int N = 100;	It should calculated through this equation: int max_iteration= (int)(1 + log(1. - 0.99)/log(1. - pow(0.5,no_samples)));
	double noise_sigma = 100;
	int N = (int)(1 + log(1. - 0.99) / log(1. - pow(0.5, no_samples))); // Maximum Iterations
	double T = 3 * noise_sigma;   // residual threshold

	int max_cnt = 0; 

	cv::Mat best_model(3, 1, CV_64FC1);

	for (int i = 0; i<N; i++)
	{
		//1. Hypotheses
		
		// Select N sample data at random from the source data
		//random sampling - 3 point
		
		int k[3] = { -1, };
		k[0] = floor((rand() % no_samples + 0)) + 0; 

		do
		{
			k[1] = floor((rand() % no_samples + 0)) + 0;

		} while (k[1] == k[0] || k[1]<0); // To avoid duplication in data

		do
		{
			k[2] = floor((rand() % no_samples + 0)) + 0;
		} while (k[2] == k[0] || k[2] == k[1] || k[2]<0); //To avoid duplication in data

		//printf("random sample : %d %d %d\n", k[0], k[1], k[2]) ;

		
		//model estimation
		// View this data as normal data and predict model parameters

		cv::Mat AA(3, 3, CV_64FC1); 
		cv::Mat BB(3, 1, CV_64FC1);
		for (int j = 0; j<3; j++)
		{
			AA.at<double>(j, 0) = vec_x[k[j]] * vec_x[k[j]]; // take 3 points from vec_x vector and put it to the first column of AA matrix
			AA.at<double>(j, 1) = vec_x[k[j]]; // take 3 points from vec_x vector and put it to the 2nd column of AA matrix
			AA.at<double>(j, 2) = 1.0; // take 3 points from vec_x vector and put it to the 3rd column of AA matrix

			BB.at<double>(j, 0) = vec_y[k[j]]; // take 3 points from vec_y vector and put it to the first column matrix BB matrix
		}

		cv::Mat AA_pinv(3, 3, CV_64FC1);
		invert(AA, AA_pinv, cv::DECOMP_SVD); 

		cv::Mat X = AA_pinv * BB; 

		 //evaluation
		// 2. Verification
		//Check that the source data fits well into the predicted model

		cv::Mat residual(100, 1, CV_64FC1); // sizeof canny edge result
		residual = cv::abs(B - A*X); // residual = y -y' = y - k(Ax+Bx+C)
		int cnt = 0;
		for (int j = 0; j<100; j++)
		{
			double data = residual.at<double>(j, 0);

			if (data < T)
			{
				cnt++;
			}
		}

		//If the predicted model fits well, we obtain a new model with valid data for this model.

		if (cnt > max_cnt)
		{
			best_model = X;
			max_cnt = cnt;
		}
	}

	//---------- Line Square fitting -------------
	cv::Mat residual = cv::abs(A*best_model - B);
	std::vector<int> vec_index;
	for (int i = 0; i<no_samples; i++)
	{
		double data = residual.at<double>(i, 0);
		if (data < T)
		{
			vec_index.push_back(i);
		}
	}

	cv::Mat A2(vec_index.size(), 3, CV_64FC1);
	cv::Mat B2(vec_index.size(), 1, CV_64FC1);

	for (size_t i = 0; i<vec_index.size(); i++)
	{
		A2.at<double>(i, 0) = vec_x[vec_index[i]] * vec_x[vec_index[i]];
		A2.at<double>(i, 1) = vec_x[vec_index[i]];
		A2.at<double>(i, 2) = 1.0;

		B2.at<double>(i, 0) = vec_y[vec_index[i]];
	}

	cv::Mat A2_pinv(3, vec_index.size(), CV_64FC1);
	invert(A2, A2_pinv, cv::DECOMP_SVD);

	cv::Mat X = A2_pinv * B2;

	//Drawing
	cv::Mat F = A*X;
	if (verbose) {
		printf("matrix F : cols =%d, rows=%d\n", F.cols, F.rows);
		std::cout << X << " " << X.type() << std::endl;
		std::cout << X.at<double>(0, 0) << " " << X.at<double>(1, 0) << std::endl;
	}

	int interval = 1;

	for (int iy = 0; iy<no_samples; iy++)
	{
		cv::circle(result, cv::Point(vec_x[iy] * interval, vec_y[iy] * interval), 3, cv::Scalar(0, 0, 255), CV_FILLED);

		double data = F.at<double>(iy, 0);

		cv::circle(result, cv::Point(vec_x[iy] * interval, data*interval), 2, cv::Scalar(0, 255, 0), CV_FILLED);
	}

	std::vector<double> vec_xx;
	std::vector<double> vec_yy;

	for (int isx = 0; isx<result.rows; isx++)
	{
		Vec3b* res2 = result.ptr<Vec3b>(isx);
		for (int isy = 0; isy<result.cols; isy++)// x=320
		{
			if (((int)res2[isy][1]) == 255)
			{
				vec_xx.push_back(isx);
				vec_yy.push_back(isy);
			}

		}
	}
	std::vector<cv::Point> pts(vec_yy.size() - 40);
	for (int i = 0; i < vec_yy.size() - 40; i++)
	{
		pts[i] = Point(vec_yy[i], vec_xx[i]);
	}
	std::sort(pts.begin(), pts.end(), object_x);
	int pt_num = 20; // 20 point were selected
	int div = (int)pts.size() / pt_num;

	if(verbose)
		printf("%d %d", pts.size(), div);

	std::vector<cv::Point> pts_extracted;
	std::vector<cv::Point> pts_subtr(20);
	for (int i = 0; i < pt_num; i++)
	{
		pts_extracted.push_back(pts[i*div]);
	}

	if(verbose)
		for (int i = 0; i < pts_extracted.size(); i++)
			printf("x_cm=%d, y_cm=%d \n", pts_extracted[i].x, pts_extracted[i].y);


	//Convert to Quaternion
#if 0
	for (int i = 0; i < pts_extracted.size(); i++) {
		double gradient = 2 * X.at<double>(0, 0)*pts_extracted[i].x + X.at<double>(1, 0);
		float radian = atan2(gradient, 1);
		float angle = (radian) * 180 / PI;
		 std::cout << angle << std::endl;
		//angle = Yaw value (in Degree)
		Quaternion(angle, Q1, Q2, Q3, Q4);
		//std::cout << "Quaternion: " << Q1 << ',' << Q2 << ',' << Q3 << ',' << Q4 << std::endl;
	}
#endif


	//////////////////////////////////
	//Rotate the Image
	double angle_s = 90;

	// get rotation matrix for rotating the image around its center
	cv::Point2f center2(result.cols / 2.0, result.rows / 2.0);
	cv::Mat rot2 = cv::getRotationMatrix2D(center2, angle_s, 1.0);
	// determine bounding rectangle
	cv::Rect bbbox = cv::RotatedRect(center2, result.size(), angle_s).boundingRect();
	// adjust transformation matrix
	rot2.at<double>(0, 2) += bbbox.width / 2.0 - center2.x;
	rot2.at<double>(1, 2) += bbbox.height / 2.0 - center2.y;

	cv::Mat rot_dst_s;
	cv::warpAffine(result, rot_dst_s, rot2, bbbox.size());
	cv::imwrite("Rotated.png", rot_dst_s);
	imshow("Rotated", rot_dst_s);

	result = rot_dst_s.clone();
	std::vector<double> vec_xxx;
	std::vector<double> vec_yyy;

	for (int isx = 0; isx<result.rows; isx++)
	{
		Vec3b* res3 = result.ptr<Vec3b>(isx);
		for (int isy = 0; isy<result.cols; isy++)// x=320
		{
			if (((int)res3[isy][1]) == 255)
			{
				vec_xxx.push_back(isx);
				vec_yyy.push_back(isy);
			}

		}
	}
	std::vector<cv::Point> pts2(vec_yyy.size() - 40);
	for (int i = 0; i < vec_yyy.size() - 40; i++)
	{
		pts2[i] = Point(vec_yyy[i], vec_xxx[i]);
	}
	std::sort(pts2.begin(), pts2.end(), object_y);
	int div2 = (int)pts2.size() / pt_num;
	if(verbose)
		printf("%d %d", pts2.size(), div2);
	std::vector<cv::Point> pts_extracted2;
	std::vector<cv::Point> pts_subtr2(20);
	for (int i = 0; i < pt_num; i++)
	{
		pts_extracted2.push_back(pts2[i*div2]);
	}

	/*for (int i = 0; i < pts2.size(); i++)
	{
	printf("x=%d, y=%d \n", pts2[i].x, pts2[i].y);
	}*/

	if(verbose)
		for (int i = 0; i < pts_extracted2.size(); i++)
			printf("x_cm=%d, y_cm=%d \n", pts_extracted2[i].x, pts_extracted2[i].y);

	// Calculate rotation about x axis
	Mat R_x = (Mat_<double>(3, 3) <<
		1, 0, 0,
		0, cos(0), -sin(0),
		0, sin(0), cos(0)
		);

	// Calculate rotation about y axis
	Mat R_y = (Mat_<double>(3, 3) <<
		cos(0), 0, sin(0),
		0, 1, 0,
		-sin(0), 0, cos(0)
		);

	// Calculate rotation about z axis
	Mat R_z = (Mat_<double>(3, 3) <<
		cos(PI), -sin(PI), 0,
		sin(PI), cos(PI), 0,
		0, 0, 1);

	// Combined rotation matrix
	Mat Ro_c = R_z;
	//std::cout<< Ro_c << std::endl;

	// Displacement Matrix
	Mat do_c = (Mat_<double>(1, 3) << 16.3, -1, 0);
	if (verbose) {
		std::cout << do_c << std::endl;
		std::cout << "check Ro_c\n" << Ro_c << std::endl;
	}

	Mat Ho_c = Mat::zeros(4, 4, Ro_c.type());
	Ro_c.copyTo(Ho_c(Range(0, 3), Range(0, 3)));
	Ho_c(Range(0, 3), Range(3, 4)) = do_c.t();
	Ho_c.at<double>(3, 3) = 1.0;
	if(verbose)
		std::cout << "check Ho_c \n" << Ho_c << std::endl;
	
#if 1
	Mat PC = cv::Mat::zeros(4, pts_extracted2.size(), CV_64F);
	for (int i = 0; i<pts_extracted2.size(); i++) {
		PC.at<double>(0, i) = pts_extracted2[i].x*cm_to_pixel;
		PC.at<double>(1, i) = pts_extracted2[i].y*cm_to_pixel;
		PC.at<double>(2, i) = 0.;
		PC.at<double>(3, i) = 1.;
	}
	PO = Ho_c * PC;
	for (int i = 0; i< PO.cols; i++) {
		PO.at<double>(0, i) = - PO.at<double>(0, i) - 7.2;
		PO.at<double>(1, i) = - PO.at<double>(1, i) - 1.1;
	}
	std::cout << "check PO.Transpose \n" << PO.col(0).t() << std::endl;
	myfile <<" "<< ""  <<"check PO.Transpose \n" << PO.col(0).t() << "\n";
#else
	for (int i = 0; i<pts_extracted2.size(); i++) {
		Mat PC = (Mat_<double>(4, 1) << pts_extracted2[i].x*cm_to_pixel, pts_extracted2[i].y*cm_to_pixel, 0, 1);
		Mat PO = Ho_c * PC;
		//std::cout<< "check PC " << PC << std::endl;
		std::cout << "check PO \n" << PO << std::endl;
	}
#endif // 1
}

static int portNumber = 6510;
static unsigned int sequenceNumber = 0;
using namespace std;
using namespace abb::egm;



//////////////////////////////////////////////////////////////////////////
// Create sensor message


class Sensor {
public:
	Sensor() {
		_robotX = 0; 
		_robotY = 0;
		_robotZ = 0;
	}

	double& x_robot_onWorldCoordinate() {
		return _robotX;
	}
	double& y_robot_onWorldCoordinate() {
		return _robotY;
	}
	double& robotZ() {
		return _robotZ;
	}

private:
	double _robotX; 
	double _robotY;
	double _robotZ;

};

void transformFromRobot2CoordA(double rx, double ry, double& wx, double& wy) {
	// For sending
	wx = -rx + 10.;
	wy = -ry + 170.;
}

void transformFromCoordA2POPlane(double ax, double ay, double& px, double& py) {
	px = -ax + 19.987003;
	py = ay;
	return;
}

void transformRecvProtoBuff2Robot(double recv_x, double recv_y, double& rx, double& ry) {
	rx = -recv_x;
	ry = recv_y;
	return;
}

void transformRecvProtoBuff2POPlane(double recv_x, double recv_y, double& rx, double& ry) {
	double wx = -recv_x;
	double wy = recv_y;
	rx = -(wx + (10 - 0.000131));
	ry = wy + (90. + 0.008980);
	return;
}


int get_goalposition(cv::Mat PO, Sensor& sensor, double* goal_xy_angle, int& goal_index) {
	const double margin = 50.; // [mm] UNIT

	int nn_index = -1; // nearest neighbor
	double nn_distance = 999999999.;

	double ax;
	double ay;
	transformFromRobot2CoordA(sensor.x_robot_onWorldCoordinate(), sensor.y_robot_onWorldCoordinate(),
		ax, ay);
	double po_x, po_y;
	transformFromCoordA2POPlane(ax, ay, po_x, po_y);
		
	for (int i = 0; i < PO.cols; i++) {
		double dx = po_x - PO.at<double>(0, i);
		double dy = po_y - PO.at<double>(1, i);
		double distance = sqrt(dx*dx + dy*dy);
		if(distance < nn_distance){
			nn_index = i;
			nn_distance = distance;
		}
	}
	if (nn_distance < 0) {
		printf("get_goalposition: wrong trajectory");
		return -1;
	}
	if (nn_index == PO.cols - 1) {
		if (nn_distance < margin) {
			printf("goal position. end program\n");
			return -1;
		}
	}
#if 1
	goal_index = nn_index+5;
#else
	int goal_index = nn_index;
	for (; goal_index < PO.cols;) {
		double dx = po_x - PO.at<double>(0, goal_index);
		double dy = po_y - PO.at<double>(1, goal_index);
		double distance = sqrt(dx*dx + dy*dy);
		if (distance > margin)
			break;
		goal_index += 1;
	}
#endif
	goal_index = std::min(PO.cols - 1, goal_index);
	goal_xy_angle[0] = PO.at<double>(0, goal_index);
	goal_xy_angle[1] = PO.at<double>(1, goal_index);
	if (nn_index < PO.cols - 1) {
		double dx = PO.at<double>(0, nn_index +1) - PO.at<double>(0, nn_index);
		double dy = PO.at<double>(1, nn_index + 1) - PO.at<double>(1, nn_index);
		goal_xy_angle[2] = atan2(dy, dx);
	}
	else {
		double dx = PO.at<double>(0, nn_index) - PO.at<double>(0, nn_index -1);
		double dy = PO.at<double>(1, nn_index) - PO.at<double>(1, nn_index -1);
		goal_xy_angle[2] = atan2(dy, dx);
	}
	return nn_index;
}


int CreateSensorMessage(EgmSensor* pSensorMessage, Sensor& sensor, cv::Mat PO, float Q1, float Q2, float Q3, float Q4)
{
	EgmHeader* header = new EgmHeader();
	header->set_mtype(EgmHeader_MessageType_MSGTYPE_CORRECTION);
	header->set_seqno(sequenceNumber++);
	header->set_tm(GetTickCount());
	if(pSensorMessage)
		pSensorMessage->set_allocated_header(header);
	EgmCartesian *pc = new EgmCartesian();
	EgmQuaternion *pq = new EgmQuaternion();
	
#if 1
	// TODO
	double goal_xy_angle[3];

	int goal_index;
	int nn_index = get_goalposition(PO, sensor, goal_xy_angle, goal_index);
	if (nn_index < 0)
		return -1;

	// TODO :
	//goal_xy[0] = 0.0;
	//goal_xy[1] = 0.0;
	double send_buf_x, send_buf_y;
	transformFromRobot2CoordA(goal_xy_angle[0], goal_xy_angle[1], send_buf_x, send_buf_y);

	pc->set_x(send_buf_x);
	pc->set_y(send_buf_y);
	//printf("goal position[%d] for xy %f,%f, \t Qwxyz %f,%f,%f,%f\n", nn_index, goal_xy[0], goal_xy[1], Q4, Q1, Q2, Q3);
	double x_robot_onControllerCoordinate;
	double y_robot_onControllerCoordinate;
	transformFromRobot2CoordA(sensor.x_robot_onWorldCoordinate(), sensor.y_robot_onWorldCoordinate(),
		x_robot_onControllerCoordinate, y_robot_onControllerCoordinate);
	printf("nn/goal/all[%d/%d/%d] NN : PO(%f, %f) -> CoordA (%f,%f) -> sendMsg (%f,%f)\n",
		nn_index, goal_index, PO.cols, goal_xy_angle[0], goal_xy_angle[1], x_robot_onControllerCoordinate, y_robot_onControllerCoordinate,
		send_buf_x, send_buf_y
		);
	//std::cout << "PO.t() = \n" << PO.t() << std::endl << std::endl;
	// Q1, Q2, Q3, Q4 is not used anymore. They will be depreciated.
	double qw, qx, qy, qz;
	static double angle0 = goal_xy_angle[2] + 99999.;
	

	if (std::abs(goal_xy_angle[2] - angle0) > 0.5 * PI / 180.) {
		
		printf("rot angle[degree] = %f\n", goal_xy_angle[2] * 180. / PI);
		myfile << "rot angle[degree] = " << goal_xy_angle[2] * 180. / PI << "\n";
		angle0 = goal_xy_angle[2];
	}

	qx = qy = 0.;
	qw = cos(goal_xy_angle[2] / 2.);
	qz = sin(goal_xy_angle[2] / 2.);
	pq->set_u0(qw); // real number. Notation.
	pq->set_u1(qx);
	pq->set_u2(qy);
	pq->set_u3(qz);
#else

	pc->set_x(0.0);
	pc->set_y(0.0);
	double recv_x_in_sendcoord, recv_y_in_sendcoord;
	transformRecvProtoBuff2Robot(sensor.x_robot_onWorldCoordinate(), sensor.y_robot_onWorldCoordinate(), recv_x_in_sendcoord, recv_y_in_sendcoord);
	printf("(%f, %f) -> (%f,%f)\n", 
		pc->x(),
		pc->y(),
		recv_x_in_sendcoord, recv_y_in_sendcoord
		);
	pq->set_u0(1.); // real number. Notation.
	pq->set_u1(0.);
	pq->set_u2(0.);
	pq->set_u3(0.);


#endif
	pc->set_z(0.0);

	EgmPose *pcartesian = new EgmPose();
	pcartesian->set_allocated_orient(pq);
	pcartesian->set_allocated_pos(pc);

	EgmPlanned *planned = new EgmPlanned();
	planned->set_allocated_cartesian(pcartesian);
	if(pSensorMessage)
		pSensorMessage->set_allocated_planned(planned);
	return 1;
}

//////////////////////////////////////////////////////////////////////////
// Display inbound robot message
void DisplayRobotMessage(EgmRobot *pRobotMessage, Sensor& sensor_value)
{
	if (pRobotMessage->has_header() && pRobotMessage->header().has_seqno() && pRobotMessage->header().has_tm() && pRobotMessage->header().has_mtype())
	{
		//printf("SeqNo=%d Tm=%u Type=%d\n", pRobotMessage->header().seqno(), pRobotMessage->header().tm(), pRobotMessage->header().mtype());
		//Display Robot x,y,z positions
		sensor_value.x_robot_onWorldCoordinate() = pRobotMessage->feedback().cartesian().pos().x();
		sensor_value.y_robot_onWorldCoordinate() = pRobotMessage->feedback().cartesian().pos().y();
		sensor_value.robotZ() = pRobotMessage->feedback().cartesian().pos().z();
		//printf("sensor value - robotX, robotY, robotZ:(%f, %f, %f)\n", sensor_value.robotX(), sensor_value.robotY(), sensor_value.robotZ());

		double ax;
		double ay;
		transformFromRobot2CoordA(sensor_value.x_robot_onWorldCoordinate(), sensor_value.y_robot_onWorldCoordinate(),
			ax, ay);

		double po_x, po_y;
		transformFromCoordA2POPlane(ax, ay, po_x, po_y);

		printf(" (%f,%f) -(transformFromRobot2CoordA)-> (%f, %f) -(tf2Plane)-> %f,%f\n",
			sensor_value.x_robot_onWorldCoordinate(),
			sensor_value.y_robot_onWorldCoordinate(),
			ax,	ay, po_x, po_y);

	}
	else{
		printf("No header\n");
	}
}

int main(int argc, char** argv)
{
	myfile.open("example.txt", ofstream::app);
	cv::VideoCapture cap(0);
	if (!cap.isOpened()) {
		printf("No Camera Detected");
		return 0;
	}
	
	SOCKET sockfd;
	struct sockaddr_in serverAddr, clientAddr;
	char protoMessage[1400];
	/* Init winsock */
	WSADATA wsaData;
	if (WSAStartup(MAKEWORD(2, 2), &wsaData) != 0)
	{
		fprintf(stderr, "Could not open Windows connection.\n");
		exit(0);
	}
	// create socket to listen on
	sockfd = ::socket(AF_INET, SOCK_DGRAM, 0);
	memset(&serverAddr, sizeof(serverAddr), 0);
	serverAddr.sin_family = AF_INET;
	serverAddr.sin_addr.s_addr = htonl(INADDR_ANY);
	//serverAddr.sin_addr.s_addr = inet_addr("127.0.0.1");
	//serverAddr.sin_addr.s_addr = inet_addr("192.168.125.1");

	serverAddr.sin_port = htons(portNumber);
	// listen on all interfaces
	bind(sockfd, (struct sockaddr *)&serverAddr, sizeof(serverAddr));
	string messageBuffer;

	bool video_capture_mode = true;
	cv::Mat PO;
	float Q1 = 1.;
	float Q2 = 0.;
	float Q3 = 0.;
	float Q4 = 0.;

	std::string video_name = "experiment.avi";
	cv::VideoWriter video_writer;
	{
		cv::Mat src0;
		cap >> src0; // get a new frame from camera
		video_writer.open(video_name, CV_FOURCC('M', 'J', 'P', 'G'),  10,  src0.size());
	}

	int n_iteration = 0;
	while(true){
		// receive message from robot
		int len = sizeof(clientAddr);
		int n = recvfrom(sockfd, protoMessage, 1400, 0, (struct sockaddr *)&clientAddr, &len);
		if (n < 0) {
			printf("Error receive message %d\n", n);
			break;
			//continue;
		}
#if 1
		if (video_capture_mode) {
			// Getting feedback from camera >>>>----------------
			cv::Mat src;
			cap >> src; // get a new frame from camera
			cv::imshow("Webcam Video", src);

			vision_process(src, PO, Q1, Q2, Q3, Q4);
			//std::cout << "check PO \n" << PO.t() << std::endl;
			//std::cout << "Quaternion: " << Q1 << ',' << Q2 << ',' << Q3 << ',' << Q4 << std::endl;
			//control_process()
			// ---------------<<< Getting feedback from camera
			if (cv::waitKey(1) >= 0) {
				PO *= 10.; // cm -> mm
				std::cout << "check PO.Transpose = \n" << PO.t() << std::endl;
				video_capture_mode = false;
			}
		}
		else {
#else
		{
#endif
			// deserialize inbound message
			EgmRobot *pRobotMessage = new EgmRobot();
			pRobotMessage->ParseFromArray(protoMessage, n);
			Sensor sensor;
			DisplayRobotMessage(pRobotMessage, sensor);
			delete pRobotMessage;

			// Create and send a sensor message >>>>----------------
#if 1
			//CreateSensorMessage(NULL, sensor, PO, Q1, Q2, Q3, Q4);
			EgmSensor *pSensorMessage = new EgmSensor();
			int h = CreateSensorMessage(pSensorMessage, sensor, PO, Q1, Q2, Q3, Q4);
			if (h < 0)
				break;
			pSensorMessage->SerializeToString(&messageBuffer);
			// send a message to the robot
			//TODO uncoment
			n = sendto(sockfd, messageBuffer.c_str(), messageBuffer.length(), 0, (struct sockaddr *)&clientAddr, sizeof(clientAddr));
			if (n < 0) {
				printf("Error send message\n");
			}
			delete pSensorMessage;

#endif
			if (n_iteration % 20 == 0) { // LOST connection with robot if try to take image every time.
				cv::Mat src;
				cap >> src; // get a new frame from camera
				video_writer << src;
				/*
				cv::imshow("Webcam Video", src);
				if (cv::waitKey(1) >= 0) // <<-- make robot work slowly, and make zerk.
					break;
				*/
			}

			if (_kbhit())
				break;
		}
		n_iteration++;
	}

	printf("end of program\n");

	cv::waitKey(0);

	return 0;
}

